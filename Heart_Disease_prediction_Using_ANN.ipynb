{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C53B5Ziiby40"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d-61vefby41"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import callbacks\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G-0akPnby41",
        "outputId": "995aa1b3-f348-49b6-cd10-72c7180f4320"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
              "0  75.0        0                       582         0                 20   \n",
              "1  55.0        0                      7861         0                 38   \n",
              "2  65.0        0                       146         0                 20   \n",
              "3  50.0        1                       111         0                 20   \n",
              "4  65.0        1                       160         1                 20   \n",
              "\n",
              "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
              "0                    1  265000.00               1.9           130    1   \n",
              "1                    0  263358.03               1.1           136    1   \n",
              "2                    0  162000.00               1.3           129    1   \n",
              "3                    0  210000.00               1.9           137    1   \n",
              "4                    0  327000.00               2.7           116    0   \n",
              "\n",
              "   smoking  time  DEATH_EVENT  \n",
              "0        0     4            1  \n",
              "1        0     6            1  \n",
              "2        1     7            1  \n",
              "3        0     7            1  \n",
              "4        0     8            1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeJ6vCVwby42",
        "outputId": "234036ee-8a62-499c-bf32-70d20c93d0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 299 entries, 0 to 298\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   age                       299 non-null    float64\n",
            " 1   anaemia                   299 non-null    int64  \n",
            " 2   creatinine_phosphokinase  299 non-null    int64  \n",
            " 3   diabetes                  299 non-null    int64  \n",
            " 4   ejection_fraction         299 non-null    int64  \n",
            " 5   high_blood_pressure       299 non-null    int64  \n",
            " 6   platelets                 299 non-null    float64\n",
            " 7   serum_creatinine          299 non-null    float64\n",
            " 8   serum_sodium              299 non-null    int64  \n",
            " 9   sex                       299 non-null    int64  \n",
            " 10  smoking                   299 non-null    int64  \n",
            " 11  time                      299 non-null    int64  \n",
            " 12  DEATH_EVENT               299 non-null    int64  \n",
            "dtypes: float64(3), int64(10)\n",
            "memory usage: 30.5 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5YaA0Euby42",
        "outputId": "bf088f12-13a2-4f6d-da72-a64aff40c68c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='DEATH_EVENT', ylabel='count'>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "#first of all let us evaluate the target and find out if our data is imbalanced or not\n",
        "\n",
        "sns.countplot(x= data[\"DEATH_EVENT\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9tisBWnby43"
      },
      "outputs": [],
      "source": [
        "#assigning values to features as X and target as y\n",
        "X=data.drop([\"DEATH_EVENT\"],axis=1)\n",
        "y=data[\"DEATH_EVENT\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_oqr2aAby43",
        "outputId": "f6f56427-43d9-4602-c21c-7c749f6f9c74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.19205124e+00, -8.71104775e-01,  1.65728387e-04, ...,\n",
              "         7.35688190e-01, -6.87681906e-01, -1.62950241e+00],\n",
              "       [-4.91308537e-01, -8.71104775e-01,  7.51463953e+00, ...,\n",
              "         7.35688190e-01, -6.87681906e-01, -1.60369074e+00],\n",
              "       [ 3.50371351e-01, -8.71104775e-01, -4.49938761e-01, ...,\n",
              "         7.35688190e-01,  1.45416070e+00, -1.59078490e+00],\n",
              "       ...,\n",
              "       [-1.33298842e+00, -8.71104775e-01,  1.52597865e+00, ...,\n",
              "        -1.35927151e+00, -6.87681906e-01,  1.90669738e+00],\n",
              "       [-1.33298842e+00, -8.71104775e-01,  1.89039811e+00, ...,\n",
              "         7.35688190e-01,  1.45416070e+00,  1.93250906e+00],\n",
              "       [-9.12148480e-01, -8.71104775e-01, -3.98321274e-01, ...,\n",
              "         7.35688190e-01,  1.45416070e+00,  1.99703825e+00]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Set up a standard scaler for the features\n",
        "col_names = list(X.columns)\n",
        "s_scaler = preprocessing.StandardScaler()\n",
        "X_df= s_scaler.fit_transform(X)\n",
        "X_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsyTavSeby44",
        "outputId": "a324b0a3-d500-4239-db40-60c486034b66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.192051</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>1.681648e-02</td>\n",
              "      <td>0.490057</td>\n",
              "      <td>-1.504036</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.629502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.491309</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>7.514640</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>7.535660e-09</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.603691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.350371</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.449939</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.038073e+00</td>\n",
              "      <td>-0.090900</td>\n",
              "      <td>-1.731046</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>-1.590785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.912148</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.486071</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-5.464741e-01</td>\n",
              "      <td>0.490057</td>\n",
              "      <td>0.085034</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.590785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.350371</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>-0.435486</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>6.517986e-01</td>\n",
              "      <td>1.264666</td>\n",
              "      <td>-4.682176</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-1.577879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>0.097867</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.537688</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>-1.109765e+00</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>1.447094</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.803451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>-0.491309</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.278215</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>6.802472e-02</td>\n",
              "      <td>-0.187726</td>\n",
              "      <td>0.539054</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>1.816357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>-1.332988</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.525979</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>1.854958</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>4.902082e+00</td>\n",
              "      <td>-0.575031</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>1.906697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>-1.332988</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.890398</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-1.263389e+00</td>\n",
              "      <td>0.005926</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.932509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>-0.912148</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.398321</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>0.585389</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>1.348231e+00</td>\n",
              "      <td>0.199578</td>\n",
              "      <td>-0.141976</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.997038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>299 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age   anaemia  creatinine_phosphokinase  diabetes  \\\n",
              "0    1.192051 -0.871105                  0.000166 -0.847579   \n",
              "1   -0.491309 -0.871105                  7.514640 -0.847579   \n",
              "2    0.350371 -0.871105                 -0.449939 -0.847579   \n",
              "3   -0.912148  1.147968                 -0.486071 -0.847579   \n",
              "4    0.350371  1.147968                 -0.435486  1.179830   \n",
              "..        ...       ...                       ...       ...   \n",
              "294  0.097867 -0.871105                 -0.537688  1.179830   \n",
              "295 -0.491309 -0.871105                  1.278215 -0.847579   \n",
              "296 -1.332988 -0.871105                  1.525979  1.179830   \n",
              "297 -1.332988 -0.871105                  1.890398 -0.847579   \n",
              "298 -0.912148 -0.871105                 -0.398321 -0.847579   \n",
              "\n",
              "     ejection_fraction  high_blood_pressure     platelets  serum_creatinine  \\\n",
              "0            -1.530560             1.359272  1.681648e-02          0.490057   \n",
              "1            -0.007077            -0.735688  7.535660e-09         -0.284552   \n",
              "2            -1.530560            -0.735688 -1.038073e+00         -0.090900   \n",
              "3            -1.530560            -0.735688 -5.464741e-01          0.490057   \n",
              "4            -1.530560            -0.735688  6.517986e-01          1.264666   \n",
              "..                 ...                  ...           ...               ...   \n",
              "294          -0.007077             1.359272 -1.109765e+00         -0.284552   \n",
              "295          -0.007077            -0.735688  6.802472e-02         -0.187726   \n",
              "296           1.854958            -0.735688  4.902082e+00         -0.575031   \n",
              "297          -0.007077            -0.735688 -1.263389e+00          0.005926   \n",
              "298           0.585389            -0.735688  1.348231e+00          0.199578   \n",
              "\n",
              "     serum_sodium       sex   smoking      time  \n",
              "0       -1.504036  0.735688 -0.687682 -1.629502  \n",
              "1       -0.141976  0.735688 -0.687682 -1.603691  \n",
              "2       -1.731046  0.735688  1.454161 -1.590785  \n",
              "3        0.085034  0.735688 -0.687682 -1.590785  \n",
              "4       -4.682176 -1.359272 -0.687682 -1.577879  \n",
              "..            ...       ...       ...       ...  \n",
              "294      1.447094  0.735688  1.454161  1.803451  \n",
              "295      0.539054 -1.359272 -0.687682  1.816357  \n",
              "296      0.312044 -1.359272 -0.687682  1.906697  \n",
              "297      0.766064  0.735688  1.454161  1.932509  \n",
              "298     -0.141976  0.735688  1.454161  1.997038  \n",
              "\n",
              "[299 rows x 12 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_df = pd.DataFrame(X_df, columns=col_names)\n",
        "X_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDHcIQNlby44",
        "outputId": "f5426e55-98b9-471c-c9c8-6ed632a15cb6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>299.0</td>\n",
              "      <td>2.406102e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.753828</td>\n",
              "      <td>-0.827980</td>\n",
              "      <td>-0.070469</td>\n",
              "      <td>0.771211</td>\n",
              "      <td>2.875411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anaemia</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.594301e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>-0.871105</td>\n",
              "      <td>1.147968</td>\n",
              "      <td>1.147968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.713120e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.576918</td>\n",
              "      <td>-0.480393</td>\n",
              "      <td>-0.342574</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>7.514640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diabetes</th>\n",
              "      <td>299.0</td>\n",
              "      <td>1.113936e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>-0.847579</td>\n",
              "      <td>1.179830</td>\n",
              "      <td>1.179830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ejection_fraction</th>\n",
              "      <td>299.0</td>\n",
              "      <td>3.341808e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-2.038387</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>0.585389</td>\n",
              "      <td>3.547716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-4.841909e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>-0.735688</td>\n",
              "      <td>1.359272</td>\n",
              "      <td>1.359272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelets</th>\n",
              "      <td>299.0</td>\n",
              "      <td>1.009969e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-2.440155</td>\n",
              "      <td>-0.520870</td>\n",
              "      <td>-0.013908</td>\n",
              "      <td>0.411120</td>\n",
              "      <td>6.008180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_creatinine</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-2.227872e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.865509</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>0.005926</td>\n",
              "      <td>7.752020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_sodium</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-8.627435e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-5.363206</td>\n",
              "      <td>-0.595996</td>\n",
              "      <td>0.085034</td>\n",
              "      <td>0.766064</td>\n",
              "      <td>2.582144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-5.940993e-18</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>-1.359272</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>0.735688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoking</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-3.861645e-17</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>-0.687682</td>\n",
              "      <td>1.454161</td>\n",
              "      <td>1.454161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>299.0</td>\n",
              "      <td>-1.069379e-16</td>\n",
              "      <td>1.001676</td>\n",
              "      <td>-1.629502</td>\n",
              "      <td>-0.739000</td>\n",
              "      <td>-0.196954</td>\n",
              "      <td>0.938759</td>\n",
              "      <td>1.997038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          count          mean       std       min       25%  \\\n",
              "age                       299.0  2.406102e-16  1.001676 -1.753828 -0.827980   \n",
              "anaemia                   299.0  3.594301e-16  1.001676 -0.871105 -0.871105   \n",
              "creatinine_phosphokinase  299.0  3.713120e-18  1.001676 -0.576918 -0.480393   \n",
              "diabetes                  299.0  1.113936e-16  1.001676 -0.847579 -0.847579   \n",
              "ejection_fraction         299.0  3.341808e-18  1.001676 -2.038387 -0.684180   \n",
              "high_blood_pressure       299.0 -4.841909e-16  1.001676 -0.735688 -0.735688   \n",
              "platelets                 299.0  1.009969e-16  1.001676 -2.440155 -0.520870   \n",
              "serum_creatinine          299.0 -2.227872e-18  1.001676 -0.865509 -0.478205   \n",
              "serum_sodium              299.0 -8.627435e-16  1.001676 -5.363206 -0.595996   \n",
              "sex                       299.0 -5.940993e-18  1.001676 -1.359272 -1.359272   \n",
              "smoking                   299.0 -3.861645e-17  1.001676 -0.687682 -0.687682   \n",
              "time                      299.0 -1.069379e-16  1.001676 -1.629502 -0.739000   \n",
              "\n",
              "                               50%       75%       max  \n",
              "age                      -0.070469  0.771211  2.875411  \n",
              "anaemia                  -0.871105  1.147968  1.147968  \n",
              "creatinine_phosphokinase -0.342574  0.000166  7.514640  \n",
              "diabetes                 -0.847579  1.179830  1.179830  \n",
              "ejection_fraction        -0.007077  0.585389  3.547716  \n",
              "high_blood_pressure      -0.735688  1.359272  1.359272  \n",
              "platelets                -0.013908  0.411120  6.008180  \n",
              "serum_creatinine         -0.284552  0.005926  7.752020  \n",
              "serum_sodium              0.085034  0.766064  2.582144  \n",
              "sex                       0.735688  0.735688  0.735688  \n",
              "smoking                  -0.687682  1.454161  1.454161  \n",
              "time                     -0.196954  0.938759  1.997038  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdA8eeHCby44"
      },
      "outputs": [],
      "source": [
        "#spliting test and training sets\n",
        "X_train, X_test, y_train,y_test = train_test_split(X_df,y,test_size=0.25,random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH37LXHSby45"
      },
      "outputs": [],
      "source": [
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
        "    patience=30, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True)\n",
        "\n",
        "# Initialising the NN\n",
        "model = Sequential()\n",
        "\n",
        "# layers\n",
        "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Compiling the ANN\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTJhuQY7by45",
        "outputId": "032c6161-d8b4-4508-a03b-1eb042294c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 32s 363ms/step - loss: 0.6930 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.6667\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6921 - accuracy: 0.6499 - val_loss: 0.6913 - val_accuracy: 0.6667\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.6102 - val_loss: 0.6904 - val_accuracy: 0.6667\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.6314 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6901 - accuracy: 0.6328 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6896 - accuracy: 0.6271 - val_loss: 0.6878 - val_accuracy: 0.6667\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6868 - accuracy: 0.6956 - val_loss: 0.6870 - val_accuracy: 0.6667\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.6435 - val_loss: 0.6862 - val_accuracy: 0.6667\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6861 - accuracy: 0.6647 - val_loss: 0.6854 - val_accuracy: 0.6667\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6864 - accuracy: 0.6427 - val_loss: 0.6847 - val_accuracy: 0.6667\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6864 - accuracy: 0.6303 - val_loss: 0.6840 - val_accuracy: 0.6667\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.6439 - val_loss: 0.6832 - val_accuracy: 0.6667\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.6544 - val_loss: 0.6824 - val_accuracy: 0.6667\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6846 - accuracy: 0.6328 - val_loss: 0.6817 - val_accuracy: 0.6667\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.6504 - val_loss: 0.6810 - val_accuracy: 0.6667\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.6054 - val_loss: 0.6803 - val_accuracy: 0.6667\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6824 - accuracy: 0.6394 - val_loss: 0.6796 - val_accuracy: 0.6667\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6822 - accuracy: 0.6358 - val_loss: 0.6789 - val_accuracy: 0.6667\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6795 - accuracy: 0.6587 - val_loss: 0.6782 - val_accuracy: 0.6667\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.6328 - val_loss: 0.6775 - val_accuracy: 0.6667\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.6393 - val_loss: 0.6769 - val_accuracy: 0.6667\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.6818 - accuracy: 0.6192 - val_loss: 0.6762 - val_accuracy: 0.6667\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6734 - accuracy: 0.6910 - val_loss: 0.6755 - val_accuracy: 0.6667\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6778 - accuracy: 0.6461 - val_loss: 0.6749 - val_accuracy: 0.6667\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6784 - accuracy: 0.6367 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6759 - accuracy: 0.6530 - val_loss: 0.6737 - val_accuracy: 0.6667\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6755 - accuracy: 0.6521 - val_loss: 0.6731 - val_accuracy: 0.6667\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.6403 - val_loss: 0.6725 - val_accuracy: 0.6667\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.6327 - val_loss: 0.6719 - val_accuracy: 0.6667\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6723 - accuracy: 0.6628 - val_loss: 0.6712 - val_accuracy: 0.6667\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.6803 - accuracy: 0.6049 - val_loss: 0.6707 - val_accuracy: 0.6667\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.6698 - accuracy: 0.6718 - val_loss: 0.6701 - val_accuracy: 0.6667\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6782 - accuracy: 0.6146 - val_loss: 0.6696 - val_accuracy: 0.6667\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6771 - accuracy: 0.6194 - val_loss: 0.6691 - val_accuracy: 0.6667\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6716 - accuracy: 0.6509 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6654 - accuracy: 0.6845 - val_loss: 0.6679 - val_accuracy: 0.6667\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6705 - accuracy: 0.6513 - val_loss: 0.6674 - val_accuracy: 0.6667\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.6756 - val_loss: 0.6669 - val_accuracy: 0.6667\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6689 - accuracy: 0.6551 - val_loss: 0.6664 - val_accuracy: 0.6667\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6756 - accuracy: 0.6168 - val_loss: 0.6659 - val_accuracy: 0.6667\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6710 - accuracy: 0.6393 - val_loss: 0.6654 - val_accuracy: 0.6667\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6699 - accuracy: 0.6430 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6669 - accuracy: 0.6562 - val_loss: 0.6644 - val_accuracy: 0.6667\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6640 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6667\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6728 - accuracy: 0.6235 - val_loss: 0.6635 - val_accuracy: 0.6667\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6747 - accuracy: 0.6132 - val_loss: 0.6630 - val_accuracy: 0.6667\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6659 - accuracy: 0.6528 - val_loss: 0.6626 - val_accuracy: 0.6667\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6679 - accuracy: 0.6422 - val_loss: 0.6621 - val_accuracy: 0.6667\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6705 - accuracy: 0.6289 - val_loss: 0.6617 - val_accuracy: 0.6667\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6729 - accuracy: 0.6169 - val_loss: 0.6613 - val_accuracy: 0.6667\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6684 - accuracy: 0.6355 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6694 - accuracy: 0.6300 - val_loss: 0.6604 - val_accuracy: 0.6667\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6650 - accuracy: 0.6469 - val_loss: 0.6600 - val_accuracy: 0.6667\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6581 - accuracy: 0.6740 - val_loss: 0.6595 - val_accuracy: 0.6667\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6710 - accuracy: 0.6198 - val_loss: 0.6591 - val_accuracy: 0.6667\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6583 - accuracy: 0.6698 - val_loss: 0.6587 - val_accuracy: 0.6667\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6613 - accuracy: 0.6563 - val_loss: 0.6583 - val_accuracy: 0.6667\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.6685 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6738 - accuracy: 0.6061 - val_loss: 0.6576 - val_accuracy: 0.6667\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6570 - accuracy: 0.6686 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6657 - accuracy: 0.6352 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6510 - accuracy: 0.6877 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6694 - accuracy: 0.6196 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6616 - accuracy: 0.6469 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6568 - accuracy: 0.6628 - val_loss: 0.6554 - val_accuracy: 0.6667\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6495 - accuracy: 0.6870 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6650 - accuracy: 0.6326 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6629 - accuracy: 0.6390 - val_loss: 0.6544 - val_accuracy: 0.6667\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6525 - accuracy: 0.6731 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6610 - accuracy: 0.6439 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.6536 - accuracy: 0.6674 - val_loss: 0.6535 - val_accuracy: 0.6667\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6657 - accuracy: 0.6272 - val_loss: 0.6533 - val_accuracy: 0.6667\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6503 - accuracy: 0.6762 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6623 - accuracy: 0.6370 - val_loss: 0.6527 - val_accuracy: 0.6667\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6660 - accuracy: 0.6248 - val_loss: 0.6525 - val_accuracy: 0.6667\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6520 - accuracy: 0.6680 - val_loss: 0.6522 - val_accuracy: 0.6667\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6604 - accuracy: 0.6413 - val_loss: 0.6519 - val_accuracy: 0.6667\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6670 - accuracy: 0.6203 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6513 - accuracy: 0.6677 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6617 - accuracy: 0.6358 - val_loss: 0.6512 - val_accuracy: 0.6667\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6586 - accuracy: 0.6445 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6547 - accuracy: 0.6555 - val_loss: 0.6507 - val_accuracy: 0.6667\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6492 - accuracy: 0.6708 - val_loss: 0.6504 - val_accuracy: 0.6667\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6657 - accuracy: 0.6223 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6556 - accuracy: 0.6511 - val_loss: 0.6500 - val_accuracy: 0.6667\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6570 - accuracy: 0.6468 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6625 - accuracy: 0.6308 - val_loss: 0.6496 - val_accuracy: 0.6667\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6700 - accuracy: 0.6092 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5921 - val_loss: 0.6492 - val_accuracy: 0.6667\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6565 - accuracy: 0.6462 - val_loss: 0.6489 - val_accuracy: 0.6667\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6497 - accuracy: 0.6642 - val_loss: 0.6486 - val_accuracy: 0.6667\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6587 - accuracy: 0.6393 - val_loss: 0.6484 - val_accuracy: 0.6667\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6495 - accuracy: 0.6637 - val_loss: 0.6482 - val_accuracy: 0.6667\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6545 - accuracy: 0.6498 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.6164 - val_loss: 0.6478 - val_accuracy: 0.6667\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6716 - accuracy: 0.6038 - val_loss: 0.6476 - val_accuracy: 0.6667\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6612 - accuracy: 0.6309 - val_loss: 0.6474 - val_accuracy: 0.6667\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6567 - accuracy: 0.6425 - val_loss: 0.6472 - val_accuracy: 0.6667\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6534 - accuracy: 0.6507 - val_loss: 0.6470 - val_accuracy: 0.6667\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6604 - accuracy: 0.6323 - val_loss: 0.6468 - val_accuracy: 0.6667\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6710 - accuracy: 0.6049 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6417 - accuracy: 0.6791 - val_loss: 0.6464 - val_accuracy: 0.6667\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6560 - accuracy: 0.6425 - val_loss: 0.6463 - val_accuracy: 0.6667\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6490 - accuracy: 0.6598 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6567 - accuracy: 0.6403 - val_loss: 0.6459 - val_accuracy: 0.6667\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6503 - accuracy: 0.6557 - val_loss: 0.6457 - val_accuracy: 0.6667\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6580 - accuracy: 0.6367 - val_loss: 0.6456 - val_accuracy: 0.6667\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6662 - accuracy: 0.6166 - val_loss: 0.6454 - val_accuracy: 0.6667\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6479 - accuracy: 0.6605 - val_loss: 0.6453 - val_accuracy: 0.6667\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6451 - val_accuracy: 0.6667\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6299 - accuracy: 0.7029 - val_loss: 0.6449 - val_accuracy: 0.6667\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6631 - accuracy: 0.6234 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6598 - accuracy: 0.6313 - val_loss: 0.6446 - val_accuracy: 0.6667\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.6683 - val_loss: 0.6445 - val_accuracy: 0.6667\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6420 - accuracy: 0.6724 - val_loss: 0.6444 - val_accuracy: 0.6667\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6569 - accuracy: 0.6376 - val_loss: 0.6443 - val_accuracy: 0.6667\n",
            "Epoch 117/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6535 - accuracy: 0.6453 - val_loss: 0.6442 - val_accuracy: 0.6667\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6557 - accuracy: 0.6400 - val_loss: 0.6440 - val_accuracy: 0.6667\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6622 - accuracy: 0.6250 - val_loss: 0.6439 - val_accuracy: 0.6667\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6638 - accuracy: 0.6212 - val_loss: 0.6438 - val_accuracy: 0.6667\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.6871 - val_loss: 0.6436 - val_accuracy: 0.6667\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6561 - accuracy: 0.6384 - val_loss: 0.6435 - val_accuracy: 0.6667\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6415 - accuracy: 0.6712 - val_loss: 0.6434 - val_accuracy: 0.6667\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 0.6424 - val_loss: 0.6433 - val_accuracy: 0.6667\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6707 - accuracy: 0.6055 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6508 - accuracy: 0.6498 - val_loss: 0.6431 - val_accuracy: 0.6667\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6508 - accuracy: 0.6497 - val_loss: 0.6430 - val_accuracy: 0.6667\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6474 - accuracy: 0.6571 - val_loss: 0.6429 - val_accuracy: 0.6667\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6619 - accuracy: 0.6251 - val_loss: 0.6428 - val_accuracy: 0.6667\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6531 - accuracy: 0.6442 - val_loss: 0.6427 - val_accuracy: 0.6667\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6620 - accuracy: 0.6246 - val_loss: 0.6426 - val_accuracy: 0.6667\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6449 - accuracy: 0.6618 - val_loss: 0.6425 - val_accuracy: 0.6667\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.6620 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5945 - val_loss: 0.6424 - val_accuracy: 0.6667\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6526 - accuracy: 0.6447 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6437 - accuracy: 0.6635 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6507 - accuracy: 0.6485 - val_loss: 0.6421 - val_accuracy: 0.6667\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6371 - accuracy: 0.6773 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6533 - accuracy: 0.6427 - val_loss: 0.6419 - val_accuracy: 0.6667\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6555 - accuracy: 0.6379 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6485 - accuracy: 0.6526 - val_loss: 0.6417 - val_accuracy: 0.6667\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6424 - accuracy: 0.6653 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.6451 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.6630 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6734 - accuracy: 0.6007 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.6729 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.6555 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6474 - accuracy: 0.6540 - val_loss: 0.6412 - val_accuracy: 0.6667\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6556 - accuracy: 0.6373 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 0.6261 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6703 - accuracy: 0.6074 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6613 - accuracy: 0.6256 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6428 - accuracy: 0.6628 - val_loss: 0.6408 - val_accuracy: 0.6667\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6569 - accuracy: 0.6343 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6530 - accuracy: 0.6421 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6415 - accuracy: 0.6650 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6524 - accuracy: 0.6433 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6586 - accuracy: 0.6308 - val_loss: 0.6405 - val_accuracy: 0.6667\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6321 - accuracy: 0.6832 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.7021 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6640 - accuracy: 0.6202 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6663 - accuracy: 0.6157 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6392 - accuracy: 0.6688 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6560 - accuracy: 0.6358 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6533 - accuracy: 0.6411 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6464 - accuracy: 0.6546 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6282 - accuracy: 0.6898 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6454 - accuracy: 0.6563 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6532 - accuracy: 0.6411 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6333 - accuracy: 0.6795 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.6433 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 0.6562 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6574 - accuracy: 0.6331 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6396 - accuracy: 0.6670 - val_loss: 0.6397 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6283 - accuracy: 0.6886 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6577 - accuracy: 0.6325 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6271 - accuracy: 0.6905 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.6115 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.6432 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6668 - accuracy: 0.6151 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6344 - accuracy: 0.6762 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6515 - accuracy: 0.6439 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6408 - accuracy: 0.6640 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6563 - accuracy: 0.6350 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6419 - accuracy: 0.6618 - val_loss: 0.6393 - val_accuracy: 0.6667\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6392 - accuracy: 0.6667 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6452 - accuracy: 0.6556 - val_loss: 0.6392 - val_accuracy: 0.6667\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6452 - accuracy: 0.6554 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.6211 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.5940 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6453 - accuracy: 0.6552 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6340 - accuracy: 0.6760 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6609 - accuracy: 0.6265 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6577 - accuracy: 0.6323 - val_loss: 0.6390 - val_accuracy: 0.6667\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6570 - accuracy: 0.6337 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.6493 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6357 - accuracy: 0.6724 - val_loss: 0.6389 - val_accuracy: 0.6667\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.6625 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6647 - accuracy: 0.6197 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6458 - accuracy: 0.6540 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6440 - accuracy: 0.6572 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6383 - accuracy: 0.6675 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6685 - accuracy: 0.6128 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.6692 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6524 - accuracy: 0.6419 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6690 - accuracy: 0.6121 - val_loss: 0.6387 - val_accuracy: 0.6667\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6354 - accuracy: 0.6724 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6599 - accuracy: 0.6285 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6533 - accuracy: 0.6402 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6575 - accuracy: 0.6328 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6476 - accuracy: 0.6505 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6439 - accuracy: 0.6571 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6512 - accuracy: 0.6440 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.6662 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6493 - accuracy: 0.6474 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6611 - accuracy: 0.6263 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6254 - accuracy: 0.6899 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6653 - accuracy: 0.6190 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6452 - accuracy: 0.6546 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.6341 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6366 - accuracy: 0.6698 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6730 - accuracy: 0.6055 - val_loss: 0.6383 - val_accuracy: 0.6667\n"
          ]
        }
      ],
      "source": [
        "# Train the ANN\n",
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 500,callbacks=[early_stopping], validation_split=0.2)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq9DUcx6by45",
        "outputId": "43282cd7-37bc-43fa-faf9-87138eab9f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val_accuracy: 66.67%\n"
          ]
        }
      ],
      "source": [
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "print(\"\\n%s: %.2f%%\" % ('val_accuracy', val_accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67GYndzmby45"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "np.set_printoptions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs0OuW9Lby45",
        "outputId": "5529606d-4d7e-4a1f-ab5e-b3229943515c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "268    0\n",
              "240    0\n",
              "278    0\n",
              "176    0\n",
              "202    0\n",
              "      ..\n",
              "24     1\n",
              "62     0\n",
              "249    0\n",
              "90     0\n",
              "50     1\n",
              "Name: DEATH_EVENT, Length: 75, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2uuJYu7by46",
        "outputId": "5f440155-a06c-4abc-af06-6d2e6ed8394a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cmap1 = sns.diverging_palette(275,150,  s=40, l=65, n=6)\n",
        "plt.subplots(figsize=(12,8))\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV6ZNZKdby46"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqL_amh7by46"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}